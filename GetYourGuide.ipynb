{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn import svm\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.data import Dataset\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset\n",
    "* import data from train / predict csv file\n",
    "* transfer Revenue/click into RPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"train.csv\", delimiter=\",\", parse_dates=True)\n",
    "predict_set = pd.read_csv(\"prediction.csv\", delimiter=\",\", parse_dates=True)\n",
    "feature_list = [\"Keyword_ID\",\"Ad_group_ID\",\"Campaign_ID\",\"Account_ID\",\"Device_ID\",\"Match_type_ID\"]\n",
    "train_set[\"RPC\"] = train_set[\"Revenue\"].values/train_set[\"Clicks\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check raw data\n",
    "Result from the below:\n",
    "* Features has no NaN values\n",
    "* The features are partly overlapped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Keyword_ID</th>\n",
       "      <th>Ad_group_ID</th>\n",
       "      <th>Campaign_ID</th>\n",
       "      <th>Account_ID</th>\n",
       "      <th>Device_ID</th>\n",
       "      <th>Match_type_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8285423</td>\n",
       "      <td>8285423</td>\n",
       "      <td>8285423</td>\n",
       "      <td>8285423</td>\n",
       "      <td>8285423</td>\n",
       "      <td>8285423</td>\n",
       "      <td>8285423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>115</td>\n",
       "      <td>487981</td>\n",
       "      <td>269480</td>\n",
       "      <td>2927</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2015-01-17</td>\n",
       "      <td>981509692733</td>\n",
       "      <td>428124648205</td>\n",
       "      <td>919168440848</td>\n",
       "      <td>604905316813</td>\n",
       "      <td>298643508640</td>\n",
       "      <td>95725474456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>281063</td>\n",
       "      <td>5188</td>\n",
       "      <td>8111</td>\n",
       "      <td>325658</td>\n",
       "      <td>2300896</td>\n",
       "      <td>3980401</td>\n",
       "      <td>3754784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date    Keyword_ID   Ad_group_ID   Campaign_ID    Account_ID  \\\n",
       "count      8285423       8285423       8285423       8285423       8285423   \n",
       "unique         115        487981        269480          2927            16   \n",
       "top     2015-01-17  981509692733  428124648205  919168440848  604905316813   \n",
       "freq        281063          5188          8111        325658       2300896   \n",
       "\n",
       "           Device_ID Match_type_ID  \n",
       "count        8285423       8285423  \n",
       "unique             3             3  \n",
       "top     298643508640   95725474456  \n",
       "freq         3980401       3754784  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[list(predict_set)].astype(str).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Keyword_ID</th>\n",
       "      <th>Ad_group_ID</th>\n",
       "      <th>Campaign_ID</th>\n",
       "      <th>Account_ID</th>\n",
       "      <th>Device_ID</th>\n",
       "      <th>Match_type_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>578012</td>\n",
       "      <td>578012</td>\n",
       "      <td>578012</td>\n",
       "      <td>578012</td>\n",
       "      <td>578012</td>\n",
       "      <td>578012</td>\n",
       "      <td>578012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>7</td>\n",
       "      <td>195748</td>\n",
       "      <td>118978</td>\n",
       "      <td>2259</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2015-04-09</td>\n",
       "      <td>981509692733</td>\n",
       "      <td>501719917851</td>\n",
       "      <td>919168440848</td>\n",
       "      <td>604905316813</td>\n",
       "      <td>298643508640</td>\n",
       "      <td>95725474456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>90792</td>\n",
       "      <td>359</td>\n",
       "      <td>519</td>\n",
       "      <td>23375</td>\n",
       "      <td>176184</td>\n",
       "      <td>283650</td>\n",
       "      <td>264997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date    Keyword_ID   Ad_group_ID   Campaign_ID    Account_ID  \\\n",
       "count       578012        578012        578012        578012        578012   \n",
       "unique           7        195748        118978          2259            16   \n",
       "top     2015-04-09  981509692733  501719917851  919168440848  604905316813   \n",
       "freq         90792           359           519         23375        176184   \n",
       "\n",
       "           Device_ID Match_type_ID  \n",
       "count         578012        578012  \n",
       "unique             3             3  \n",
       "top     298643508640   95725474456  \n",
       "freq          283650        264997  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_set.astype(str).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword_ID in predict is subset in train: False\n",
      "Ad_group_ID in predict is subset in train: False\n",
      "Campaign_ID in predict is subset in train: False\n",
      "Account_ID in predict is subset in train: True\n",
      "Device_ID in predict is subset in train: True\n",
      "Match_type_ID in predict is subset in train: True\n"
     ]
    }
   ],
   "source": [
    "# check the key words etc are overlapped or not \n",
    "for feature in feature_list:\n",
    "    t = set(train_set[feature].values)\n",
    "    p = set(predict_set[feature].values)\n",
    "    print(feature,\"in predict is subset in train:\",p.issubset(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check train set isnull :\n",
      " Date             False\n",
      "Keyword_ID       False\n",
      "Ad_group_ID      False\n",
      "Campaign_ID      False\n",
      "Account_ID       False\n",
      "Device_ID        False\n",
      "Match_type_ID    False\n",
      "Revenue          False\n",
      "Clicks           False\n",
      "Conversions      False\n",
      "RPC              False\n",
      "dtype: bool\n",
      "check predict set isnull: \n",
      " Date             False\n",
      "Keyword_ID       False\n",
      "Ad_group_ID      False\n",
      "Campaign_ID      False\n",
      "Account_ID       False\n",
      "Device_ID        False\n",
      "Match_type_ID    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# check no null data inside the train/prediction set \n",
    "print(\"check train set isnull :\\n\",train_set.isnull().any())\n",
    "print(\"check predict set isnull: \\n\",predict_set.isnull().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imbalanced dataset\n",
    "\n",
    "If do not do upsample / downsample, the model will bias to the majority ones those without revenues\n",
    "\n",
    "In this assigment,simply returning 0 for all the inputs could reach 98% correctness. This is obviously wrong.\n",
    "\n",
    "From the test blow we can't be so sure what is the best porportion for revenue vs non-revenue, since the error is no longer smaller the better\n",
    "\n",
    "\n",
    "* downsample the majority type\n",
    "* upsample the minority type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revenue 160649\n",
      "No revenue 8124774\n",
      "Unbalanced dataset for revenue portion 0.019389354049877718\n"
     ]
    }
   ],
   "source": [
    "# unbalanced dataset\n",
    "revenue = train_set[train_set[\"RPC\"]>0].shape[0]\n",
    "no_revenue= train_set[train_set[\"RPC\"] == 0].shape[0]\n",
    "print(\"Revenue\",revenue)\n",
    "print(\"No revenue\",no_revenue)\n",
    "print('Unbalanced dataset for revenue portion',(revenue/(revenue+no_revenue)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  \n",
    "- keep all the minority dataset  \n",
    "- downsample from the rest of majority dataset \n",
    "The problem here:\n",
    "    We might sample the bias majority prediction, losing important information for zero-revenue part.\n",
    "\"\"\"\n",
    "def balanced_dataset(major_portion,df):\n",
    "    train_minor = df[df[\"Revenue\"] > 0]\n",
    "    minor_size = train_minor.shape[0]\n",
    "    train_major = df[df[\"Revenue\"] == 0].sample(n=minor_size*major_portion)\n",
    "    balanced_set = pd.concat([train_major, train_minor]).sample(frac = 1.0)\n",
    "    print('New balanced dataset revenue portion is:',train_minor.shape[0]/balanced_set.shape[0])\n",
    "    return balanced_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New balanced dataset revenue portion is: 0.5\n",
      "RMSE 3298.360783391489 \n",
      " [3133.0743912363396, 3258.196270135476, 3765.649474937612, 2966.517535499931, 3399.0610471182035, 3267.665981421369]\n",
      "New balanced dataset revenue portion is: 0.3333333333333333\n",
      "RMSE 2792.6950797058275 \n",
      " [2811.844434846364, 2687.1671026818303, 2735.649999767808, 3194.342030105784, 2681.039830449805, 2646.127080383377]\n",
      "New balanced dataset revenue portion is: 0.25\n",
      "RMSE 2501.040632407004 \n",
      " [2365.946348824716, 2755.8406000794753, 2407.979587151054, 2473.8162038259097, 2247.1384106369032, 2755.5226439239646]\n",
      "New balanced dataset revenue portion is: 0.2\n",
      "RMSE 2267.0538457265598 \n",
      " [2054.802269050211, 2085.712377865449, 2501.4641259292757, 2147.2887688018077, 2495.0086069723206, 2318.046925740294]\n",
      "New balanced dataset revenue portion is: 0.16666666666666666\n",
      "RMSE 2071.9955812682742 \n",
      " [2049.0301550490435, 2371.2611849072737, 1946.3336773814083, 1902.0940301952123, 2056.314209516797, 2106.9402305599124]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test on different revenue proportion with simple linear regression\n",
    "\"\"\"\n",
    "for portion in range(1,6):\n",
    "    balanced_set = balanced_dataset(portion,train_set)\n",
    "    X = balanced_set[feature_list]\n",
    "    y = balanced_set['RPC']\n",
    "    clf = LinearRegression()\n",
    "    error_list= []\n",
    "    for _ in range(6):\n",
    "        x_train, x_validate, y_train, y_validate = train_test_split(X,y,test_size=0.2,shuffle=True)\n",
    "        clf.fit(x_train,y_train)\n",
    "        y_pred=clf.predict(x_validate)\n",
    "        error = np.sqrt(metrics.mean_squared_error(y_validate, y_pred))\n",
    "        error_list.append(error)\n",
    "    print(\"RMSE\",sum(error_list)/len(error_list),\"\\n\",error_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess category feature \n",
    "### Scikit-Learn \n",
    "* OneHotEncoder:\n",
    "\n",
    "    The input to this transformer should be a matrix of integers, denoting the values taken on by categorical (discrete) features. \n",
    "    The output will be a sparse matrix where each column corresponds to one possible value of one feature. It is assumed that input features take on values in the range \\[0, n_values)\n",
    "\n",
    "\n",
    "* LabelEncoder: \n",
    "\n",
    "    A utility class to help normalize labels such that they contain only values between 0 and n_classes-1\n",
    "\n",
    "! Problem : \n",
    "    Use OneHotEncoder or LabelEncoder in large dataset(billions of text tags) could slow down the convert\n",
    "\n",
    "\n",
    "### Pandas\n",
    "* factorize:\n",
    "\n",
    "    Label those the hashed features and return continuous numeric tags represent different hash code\n",
    "\n",
    "! Problem :\n",
    "    For each feature those data are not real continuous numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Keyword_ID</th>\n",
       "      <th>Ad_group_ID</th>\n",
       "      <th>Campaign_ID</th>\n",
       "      <th>Account_ID</th>\n",
       "      <th>Device_ID</th>\n",
       "      <th>Match_type_ID</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Clicks</th>\n",
       "      <th>Conversions</th>\n",
       "      <th>RPC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8285423</td>\n",
       "      <td>8285423</td>\n",
       "      <td>8285423</td>\n",
       "      <td>8285423</td>\n",
       "      <td>8285423</td>\n",
       "      <td>8285423</td>\n",
       "      <td>8285423</td>\n",
       "      <td>8285423</td>\n",
       "      <td>8285423</td>\n",
       "      <td>8285423</td>\n",
       "      <td>8285423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>115</td>\n",
       "      <td>487981</td>\n",
       "      <td>269480</td>\n",
       "      <td>2927</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10907</td>\n",
       "      <td>255</td>\n",
       "      <td>45</td>\n",
       "      <td>30184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2015-01-17</td>\n",
       "      <td>28</td>\n",
       "      <td>240</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>281063</td>\n",
       "      <td>5188</td>\n",
       "      <td>8111</td>\n",
       "      <td>325658</td>\n",
       "      <td>2300896</td>\n",
       "      <td>3980401</td>\n",
       "      <td>3754784</td>\n",
       "      <td>8124774</td>\n",
       "      <td>6510187</td>\n",
       "      <td>8123396</td>\n",
       "      <td>8124774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date Keyword_ID Ad_group_ID Campaign_ID Account_ID Device_ID  \\\n",
       "count      8285423    8285423     8285423     8285423    8285423   8285423   \n",
       "unique         115     487981      269480        2927         16         3   \n",
       "top     2015-01-17         28         240           3          7         0   \n",
       "freq        281063       5188        8111      325658    2300896   3980401   \n",
       "\n",
       "       Match_type_ID  Revenue   Clicks Conversions      RPC  \n",
       "count        8285423  8285423  8285423     8285423  8285423  \n",
       "unique             3    10907      255          45    30184  \n",
       "top                0      0.0        2           0      0.0  \n",
       "freq         3754784  8124774  6510187     8123396  8124774  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Category feature in Pandas:\n",
    "\"\"\"\n",
    "def category_in_pandas(df,feature_list):\n",
    "    train_category = df\n",
    "    train_category[feature_list] = df[feature_list].apply(lambda x : pd.factorize(x)[0])\n",
    "    train_category[feature_list].astype(str).describe()\n",
    "    return train_category\n",
    "category_in_pandas(train_set,feature_list).astype(str).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regession(clf,X,y,test_size=0.2,shuffle=True):\n",
    "    x_train, x_validate, y_train, y_validate = train_test_split(X,y,test_size=test_size,shuffle=shuffle)\n",
    "    clf.fit(x_train,y_train)\n",
    "    y_pred=clf.predict(x_validate)\n",
    "    print(\"RMSE\",np.sqrt(metrics.mean_squared_error(y_validate, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 1872.7391633816183\n",
      "RMSE 2060.077294219344\n",
      "RMSE 2295.499594305379\n",
      "RMSE 1897.4320596887217\n",
      "RMSE 2129.8499058744824\n"
     ]
    }
   ],
   "source": [
    "category_set = category_in_pandas(balanced_set,feature_list)\n",
    "X,y = category_set[feature_list],category_set['RPC']\n",
    "clf = LinearRegression()\n",
    "for _ in range(5):\n",
    "    regession(clf,X,y,test_size=0.2,shuffle=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "New balanced dataset revenue portion is: 0.14285714285714285 \n",
    "## benchmark\n",
    "- before, raw data\n",
    "RMSE 2071.9955812682742 \n",
    "\n",
    "- after, pandas \"factorize\":\n",
    "RMSE 1781.2937365108407\n",
    "\n",
    "need better improvment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New balanced dataset revenue portion is: 0.14285714285714285\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "prepare data set\n",
    "\"\"\"\n",
    "balanced_set = balanced_dataset(6,train_set)\n",
    "X,y = balanced_set[feature_list],balanced_set['RPC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 1907.8318035057887\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Category feature in OneHotEncoder\n",
    "\"\"\"\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "encoder.fit(X)\n",
    "# encoder.active_features_\n",
    "# encoder.transform(X)\n",
    "x_code_train = encoder.transform(x_train)\n",
    "x_code_validate = encoder.transform(x_validate)\n",
    "\n",
    "clf = LinearRegression()\n",
    "clf.fit(x_code_train,y_train)\n",
    "y_pred=clf.predict(x_code_validate)\n",
    "print(\"RMSE\",np.sqrt(metrics.mean_squared_error(y_validate, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 2138.3278915921196\n",
      "RMSE 1867.2334088621135\n",
      "RMSE 1818.793464146461\n",
      "RMSE 1768.104573138274\n",
      "RMSE 1766.2322373775003\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Category feature in LabelEncoder on feature_list\n",
    "\"\"\"\n",
    "def create_label_encoder(df):\n",
    "    le = LabelEncoder()\n",
    "    new_X = pd.DataFrame()\n",
    "    for head in list(df):\n",
    "        new_X[head] = le.fit_transform(df[head])\n",
    "    return new_X\n",
    "\n",
    "new_X = create_label_encoder(X)\n",
    "\n",
    "clf = LinearRegression()\n",
    "for _ in range(5):\n",
    "    x_train, x_validate, y_train, y_validate = train_test_split(new_X,y,test_size=0.2,shuffle=True)\n",
    "    clf.fit(x_train,y_train)\n",
    "    y_pred=clf.predict(x_validate)\n",
    "    print(\"RMSE\",np.sqrt(metrics.mean_squared_error(y_validate, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using TensorFlow\n",
    "* numeric_column+GradientDescentOptimizer+LinearRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_input_fn(features, targets, batch_size=50, shuffle=True, num_epochs=None):\n",
    "    features = {key:np.array(value) for key,value in dict(features).items()}                                           \n",
    "    ds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit\n",
    "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=5000)\n",
    "    return ds.make_one_shot_iterator().get_next()\n",
    "\n",
    "\n",
    "def train_model(df,learning_rate, steps, batch_size):\n",
    "    \"\"\"\n",
    "    numeric_column+GradientDescentOptimizer+LinearRegressor\n",
    "    \"\"\"\n",
    "    periods = 10\n",
    "    steps_per_period = steps / periods\n",
    "    \n",
    "    input_feature = ['Keyword_ID']#,'Ad_group_ID'\n",
    "    bucket_size = [487981] #,269480\n",
    "    my_feature_column = df[input_feature]\n",
    "    targets = df[\"RPC\"]\n",
    "\n",
    "    feature_columns = []\n",
    "    for feature,bucket in zip(input_feature,bucket_size):\n",
    "        categorical_feature = tf.feature_column.numeric_column(feature)\n",
    "        feature_columns.append(categorical_feature)\n",
    "#         categorical_feature = tf.feature_column.categorical_column_with_identity(key=feature, num_buckets=bucket, default_value=0)\n",
    "#         feature_columns.append(tf.feature_column.embedding_column(categorical_feature,math.ceil(bucket**0.25)))\n",
    "    \n",
    "    # Create input functions\n",
    "    training_input_fn = lambda:my_input_fn(my_feature_column,targets,batch_size=batch_size)\n",
    "    prediction_input_fn = lambda: my_input_fn(my_feature_column,targets,num_epochs=1)\n",
    "    \n",
    "    # Create a linear regressor object.\n",
    "    my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    #     my_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
    "    linear_regressor = tf.estimator.LinearRegressor(feature_columns=feature_columns,optimizer=my_optimizer)\n",
    "\n",
    "    # Train the model, but do so inside a loop so that we can periodically assess\n",
    "    # loss metrics.\n",
    "    print(\"Training model...\")\n",
    "    print(\"RMSE (on training data):\")\n",
    "    for period in range (0, periods):\n",
    "        linear_regressor.train(\n",
    "            input_fn=training_input_fn,\n",
    "            steps=steps_per_period\n",
    "        )\n",
    "        # Take a break and compute predictions.\n",
    "        predictions = linear_regressor.predict(input_fn=prediction_input_fn)\n",
    "        predictions = np.array([item['predictions'][0] for item in predictions])\n",
    "        # Compute loss.\n",
    "        root_mean_squared_error = math.sqrt(\n",
    "            metrics.mean_squared_error(predictions, targets))\n",
    "        # Occasionally print the current loss.\n",
    "        print((\"  period %02d : %0.2f\") % (period, root_mean_squared_error))\n",
    "    print(\"Model training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New balanced dataset revenue portion is: 0.14285714285714285\n",
      "(1124543, 11)\n",
      "Training model...\n",
      "RMSE (on training data):\n",
      "  period 00 : 1935.73\n",
      "  period 01 : 1935.73\n",
      "  period 02 : 2005.84\n",
      "  period 03 : 1935.73\n",
      "  period 04 : 2004.67\n",
      "  period 05 : 1935.73\n",
      "  period 06 : 1935.73\n",
      "  period 07 : 2004.53\n",
      "  period 08 : 2005.28\n",
      "  period 09 : 1935.73\n",
      "Model training finished.\n"
     ]
    }
   ],
   "source": [
    "# input data \n",
    "balanced_set = balanced_dataset(6,train_set)\n",
    "category_set = category_in_pandas(balanced_set,feature_list)\n",
    "print(category_set.shape)\n",
    "train_model(balanced_set,learning_rate=0.001,steps=200,batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compared with all those above different approches\n",
    "raw data + LabelEncoder + LinearRegression from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New balanced dataset revenue portion is: 0.16666666666666666\n",
      "RMSE 1995.1941323015783\n",
      "New balanced dataset revenue portion is: 0.14285714285714285\n",
      "RMSE 2190.773711071997\n",
      "New balanced dataset revenue portion is: 0.125\n",
      "RMSE 1748.564367011215\n",
      "New balanced dataset revenue portion is: 0.1111111111111111\n",
      "RMSE 1634.8047197832377\n",
      "New balanced dataset revenue portion is: 0.1\n",
      "RMSE 1583.5438036439093\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119cddc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distribution  count    578011.000000\n",
      "mean        264.062135\n",
      "std          68.143324\n",
      "min          50.293344\n",
      "25%         217.312879\n",
      "50%         267.529078\n",
      "75%         312.869430\n",
      "max         428.998002\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train_set = pd.read_csv(\"train.csv\", delimiter=\",\", parse_dates=True)\n",
    "predict_set = pd.read_csv(\"prediction.csv\", delimiter=\",\", parse_dates=True)\n",
    "feature_list = [\"Keyword_ID\",\"Ad_group_ID\",\"Campaign_ID\",\"Account_ID\",\"Device_ID\",\"Match_type_ID\"]\n",
    "train_set[\"RPC\"] = train_set[\"Revenue\"].values/train_set[\"Clicks\"].values\n",
    "\n",
    "for major_portion in range(5,10):\n",
    "    balanced_set = balanced_dataset(major_portion,train_set)\n",
    "    X,y = balanced_set[feature_list],balanced_set['RPC']\n",
    "    Z = pd.concat([X, predict_set[feature_list]])\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    new_Z = pd.DataFrame()\n",
    "    for head in list(Z):\n",
    "        new_Z[head] = le.fit_transform(Z[head])\n",
    "\n",
    "    new_X = new_Z.iloc[0:X.shape[0],]\n",
    "    new_predict = new_Z.iloc[X.shape[0]:-1,]\n",
    "\n",
    "    clf = LinearRegression()\n",
    "    for _ in range(35):\n",
    "        x_train, x_validate, y_train, y_validate = train_test_split(new_X,y,test_size=0.2,shuffle=True)\n",
    "        clf.fit(x_train,y_train)\n",
    "        y_pred=clf.predict(x_validate)\n",
    "    print(\"RMSE\",np.sqrt(metrics.mean_squared_error(y_validate, y_pred)))\n",
    "\n",
    "    prediction = clf.predict(new_predict)\n",
    "\n",
    "result = pd.Series(prediction)\n",
    "result.plot.box()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(\"distribution \",result.describe())\n",
    "result.to_csv(\"result.csv\",index=False,header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
